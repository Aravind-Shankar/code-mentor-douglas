{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streaming helper\n",
    "\n",
    "async def astream(invocable, inputs, *args, **kwargs):\n",
    "    async for chunk in invocable.astream(inputs, *args, **kwargs):\n",
    "        print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorstore database generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code splits into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 1257.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, os.path as osp\n",
    "import glob\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "repo_path = \".\\\\PathTracerAP\"\n",
    "\n",
    "loader = DirectoryLoader(repo_path, \"*.*\", loader_cls=TextLoader, show_progress=True, use_multithreading=True)\n",
    "source_files = loader.load()\n",
    "\n",
    "cpp_splitter = RecursiveCharacterTextSplitter.from_language(language=Language.CPP, chunk_size=200, chunk_overlap=10)\n",
    "code_chunks = cpp_splitter.split_documents(source_files)\n",
    "print(len(code_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information chain creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "gpt4all_embd = GPT4AllEmbeddings(model_name=\"all-MiniLM-L6-v2.gguf2.f16.gguf\")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "info_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI agent tasked with processing chunks from a codebase. Your objective is to thoroughly understand the information contained in each chunk and return a CONCISE summary. You must provide your answer strictly in BULLET POINTS - all output lines must start with the character '•'. Do NOT use any other sentence formatting, and do NOT include any introductory or concluding statements.\"),\n",
    "    (\"user\", \"The code chunk you will need to process is:\\n{code_chunk}\")\n",
    "])\n",
    "\n",
    "info_chain = info_prompt_template | llm\n",
    "# print(code_chunks[0].page_content, '\\n')\n",
    "# await astream(info_chain, code_chunks[0].page_content)\n",
    "# print(code_chunks[1].page_content, '\\n')\n",
    "# await astream(info_chain, code_chunks[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• The code chunk includes several header files and defines a macro to enable CUDA functionality.\n",
      "• The namespace Common defines an entity index type and structs for Vertex, Triangle, and BoundingBox.\n",
      "• The namespace Geometry defines structs for Vertex and Triangle.\n",
      "• The BoundingBox struct has methods for initializing and updating its bounds.\n"
     ]
    }
   ],
   "source": [
    "def parse_bullet_points(text):\n",
    "    bullet_char = '•'\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    lines = list(filter(lambda line: line.startswith(bullet_char), lines))\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "text = \"\"\"\n",
    "Summary is:\n",
    "• The code chunk includes several header files and defines a macro to enable CUDA functionality.\n",
    "• The namespace Common defines an entity index type and structs for Vertex, Triangle, and BoundingBox.\n",
    "• The namespace Geometry defines structs for Vertex and Triangle.\n",
    "• The BoundingBox struct has methods for initializing and updating its bounds.\n",
    "\"\"\"\n",
    "\n",
    "print(parse_bullet_points(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "heirarchy_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an AI agent tasked with combining 2 code summaries. Your task is to merge two summaries of different code base parts into a single, clear, and comprehensive knowledge base. Combine overlapping details, organize content logically by grouping related functionalities, include all unique information from both summaries, use concise technical language, maintain context and purpose of each code chunk, and ensure consistency in terminology and formatting.You must provide your response strictly in BULLET POINTS - all output lines must start with the character '•'. Do NOT use any other sentence formatting. Do NOT include any introductory or concluding statements. DO NOT use the words like - 'summary' or 'chunk' in your response.\n",
    "\"\"\"),\n",
    "    (\"user\", \"The two summaries you will need to process are:\\n summary 1:{summary_1} \\n summary 2:{summary_2}\")\n",
    "])\n",
    "\n",
    "heirarchy_chain = heirarchy_prompt_template | llm\n",
    "\n",
    "summary_1 = \"\"\"\n",
    "• The code chunk includes several directives and includes, indicating that it is a C++ header file.\n",
    "• The pragma once directive indicates that the file should be included only once in the entire program.\n",
    "• The #include <iostream> directive includes the standard output stream functions from the C++ standard library.\n",
    "• The #include <vector> directive includes the vector data structure from the C++ standard library.\n",
    "• The #define GLM_FORCE_CUDA directive enables NVIDIA CUDA optimization for the glm library.\n",
    "• The #include <glm/glm.hpp> and #include <glm/gtc/matrix_transform.hpp> directives include the glm library, which provides geometric computations and transformations.\n",
    "• The #include \"Config.h\" directive includes a configuration file.\n",
    "• The namespace Common defines a new namespace named Common.\n",
    "• The struct IndexRange defines an index range structure.\n",
    "• The struct Vertex defines a vertex structure with position, normal, and uv components.\n",
    "• The struct Triangle defines a triangle structure with vertex indices.\n",
    "• The struct BoundingBox defines a bounding box structure with minimum and maximum coordinates in each dimension.\n",
    "• The BoundingBox constructor initializes the bounding box with arbitrary large values, and the update method updates the bounds based on the position of a vertex.namespace SceneElements\n",
    "\"\"\"\n",
    "summary_2 = \"\"\"\n",
    "• The code chunk is a part of a 3D graphics library, specifically the namespace \"SceneElements\".\n",
    "• The code defines several structures: Material, Mesh, Model, EntityType, Voxel3DIndex, Voxel, Grid.\n",
    "• The Material structure has fields for material type (DIFFUSE, SPECULAR, etc.), refractive index, and phong exponent.\n",
    "• The Mesh structure has fields for vertex indices, triangle indices, and bounding box.\n",
    "• The Model structure has fields for grid index, mesh index, model-to-world and world-to-model matrices, and material.\n",
    "• The EntityType enum defines four values: MODEL, SCENE, TRIANGLE, SPHERE.\n",
    "• The Voxel3DIndex struct has fields for x, y, and z indices.\n",
    "• The Voxel struct has fields for entity index range and entity type.\n",
    "• The Grid struct has fields for voxel indices, entity type, and entity index.\n",
    "• The code also defines an enum for spatial acceleration.\n",
    "\"\"\"\n",
    "#await astream(heirarchy_chain, {\"summary_1\":summary_1, \"summary_2\":summary_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build global vector store, part 1 - within files\n",
    "# Per file: summarize chunks, combine summaries, put summaries across all levels in vector store\n",
    "\n",
    "global_summary_doc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PathTracerAP\\\\Debug_Visualizer.h': 3,\n",
       " 'PathTracerAP\\\\Config.h': 3,\n",
       " 'PathTracerAP\\\\Experimentation.h': 102,\n",
       " 'PathTracerAP\\\\GPUMemoryPool.h': 6,\n",
       " 'PathTracerAP\\\\main.cpp': 4,\n",
       " 'PathTracerAP\\\\Primitive.h': 17,\n",
       " 'PathTracerAP\\\\Scene.cpp': 130,\n",
       " 'PathTracerAP\\\\Renderer.cpp': 187,\n",
       " 'PathTracerAP\\\\Renderer.h': 9,\n",
       " 'PathTracerAP\\\\Scene.h': 7,\n",
       " 'PathTracerAP\\\\utility.h': 45}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1. Organize chunks by file\n",
    "chunks_by_file = {}\n",
    "\n",
    "for chunk in code_chunks:\n",
    "    file_path = chunk.metadata[\"source\"]\n",
    "    if file_path not in chunks_by_file:\n",
    "        chunks_by_file[file_path] = []\n",
    "    chunks_by_file[file_path].append(chunk)\n",
    "\n",
    "{file_path: len(chunks) for file_path, chunks in chunks_by_file.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: PathTracerAP\\Debug_Visualizer.h (3 chunks)...\n",
      "- Summarizing individual chunks\n",
      "\tChunk 1 / 3\n",
      "\tChunk 2 / 3\n",
      "\tChunk 3 / 3\n",
      "- Building hierarchical summaries\n",
      "\tLevel 1\n",
      "\tLevel 2\n",
      "PathTracerAP\\Debug_Visualizer.h\n",
      "• #pragma once\n",
      "• #include \"GL/glew.h\"\n",
      "• #include \"GLFW/glfw3.h\"\n",
      "• #include <glm/glm.hpp>\n",
      "• #include <glm/gtc/matrix_transform.hpp>\n",
      "• #include <glm/gtc/type_ptr.hpp>\n",
      "• #include \"Renderer.h\"\n",
      "• #ifdef ENABLE_VISUALIZER\n",
      "•  #endif\n",
      "\n",
      "{'source': 'PathTracerAP\\\\Debug_Visualizer.h'}\n",
      "*********************\n",
      "• The code chunk includes various headers and libraries for graphics programming:\n",
      "\t+ OpenGL (GLEW)\n",
      "\t+ GLFW (for windowing and input handling)\n",
      "\t+ GLM (a mathematics library for vectors, matrices, and transformations)\n",
      "\t• Additionally, it includes a custom header file \"Renderer.h\"\n",
      "\n",
      "{'source': 'PathTracerAP\\\\Debug_Visualizer.h'}\n",
      "*********************\n",
      "• This code snippet is a preprocessor directive that checks if a constant `ENABLE_VISUALIZER` is defined. \n",
      "• If `ENABLE_VISUALIZER` is enabled, the code within this block will be compiled.\n",
      "\n",
      "{'source': 'PathTracerAP\\\\Debug_Visualizer.h'}\n",
      "*********************\n",
      "• Defines a function `launch_visualizer` that takes a pointer to `RenderData` as an argument\n",
      "• Function signature suggests it launches some kind of visualizer or renderer, possibly using the data provided in `render_data`\n",
      "• The `#endif` directive indicates this chunk may be part of a larger conditional compilation block\n",
      "\n",
      "{'source': 'PathTracerAP\\\\Debug_Visualizer.h'}\n",
      "*********************\n",
      "PathTracerAP\\Debug_Visualizer.h\n",
      "• #pragma once\n",
      "• #include \"GL/glew.h\"\n",
      "• #include \"GLFW/glfw3.h\"\n",
      "• #include <glm/glm.hpp>\n",
      "• #include <glm/gtc/matrix_transform.hpp>\n",
      "• #include <glm/gtc/type_ptr.hpp>\n",
      "• #include \"Renderer.h\"\n",
      "• #ifdef ENABLE_VISUALIZER\n",
      "• #endif \n",
      "• Includes:\n",
      "\n",
      "{'source': 'PathTracerAP\\\\Debug_Visualizer.h'}\n",
      "*********************\n",
      "PathTracerAP\\Debug_Visualizer.h\n",
      "• Defines a preprocessor directive that checks if a constant `ENABLE_VISUALIZER` is defined.\n",
      "• If `ENABLE_VISUALIZER` is enabled, the code within this block will be compiled.\n",
      "• The code defines a function `launch_visualizer` that takes a pointer to `RenderData` as an argument.\n",
      "• Function signature suggests it launches some kind of visualizer or renderer, possibly using the data provided in `render_data`.\n",
      "• May be part of a larger conditional compilation block, indicated by the presence of the `#endif` directive.\n",
      "• The preprocessor directive is used to conditionally compile code that depends on the value of `ENABLE_VISUALIZER`.\n",
      "\n",
      "{'source': 'PathTracerAP\\\\Debug_Visualizer.h'}\n",
      "*********************\n",
      "PathTracerAP\\Debug_Visualizer.h\n",
      "• #pragma once\n",
      "• #include \"GL/glew.h\"\n",
      "• #include \"GLFW/glfw3.h\"\n",
      "• #include <glm/glm.hpp>\n",
      "• #include <glm/gtc/matrix_transform.hpp>\n",
      "• #include <glm/gtc/type_ptr.hpp>\n",
      "• #include \"Renderer.h\"\n",
      "• Defines a preprocessor directive that checks if a constant `ENABLE_VISUALIZER` is defined.\n",
      "• If `ENABLE_VISUALIZER` is enabled, the code within this block will be compiled.\n",
      "• Includes function definition:\n",
      "• May be part of a larger conditional compilation block, indicated by the presence of the `#endif` directive.\n",
      "\n",
      "{'source': 'PathTracerAP\\\\Debug_Visualizer.h'}\n",
      "*********************\n"
     ]
    }
   ],
   "source": [
    "# 2. For each file, build hierarchical summaries and store in global list\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from tqdm import tqdm\n",
    "\n",
    "for file_path, chunks in chunks_by_file.items():\n",
    "    if file_path != 'PathTracerAP\\\\Debug_Visualizer.h':\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing file: {file_path} ({len(chunks)} chunks)...\")\n",
    "\n",
    "    print(\"- Summarizing individual chunks\")\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"\\tChunk {i+1} / {len(chunks)}\")\n",
    "        summary = info_chain.invoke(chunk.page_content)\n",
    "        summary_doc = Document(page_content=summary, metadata=chunk.metadata)\n",
    "        global_summary_doc_list.append(summary_doc)\n",
    "\n",
    "    print(\"- Building hierarchical summaries\")\n",
    "\n",
    "    read_buffer = [summary_doc for summary_doc in global_summary_doc_list]\n",
    "    merge_buffer = []\n",
    "\n",
    "    level = 1\n",
    "    while len(read_buffer) > 1:\n",
    "        print(f\"\\tLevel {level}\")\n",
    "\n",
    "        for i in range(0, len(read_buffer)-1, 2):\n",
    "            print(f\"\\t\\tEntries ({i},{i+1}) out of {len(read_buffer)}\")\n",
    "            doc1, doc2 = read_buffer[i], read_buffer[i+1]\n",
    "            common_meta = doc1.metadata\n",
    "            info = heirarchy_chain.invoke({\n",
    "                \"summary_1\": doc1.page_content,\n",
    "                \"summary_2\": doc2.page_content\n",
    "            })\n",
    "            info_points = parse_bullet_points(info)\n",
    "\n",
    "            merge_buffer.append(Document(\n",
    "                page_content=common_meta[\"source\"]+\"\\n\"+info_points,\n",
    "                metadata=common_meta\n",
    "            ))\n",
    "\n",
    "        read_buffer.clear()\n",
    "        read_buffer.extend(merge_buffer)\n",
    "        global_summary_doc_list.extend(merge_buffer)\n",
    "        level += 1\n",
    "        merge_buffer.clear()\n",
    "\n",
    "for doc in global_summary_doc_list:\n",
    "    print(doc.page_content)\n",
    "    print()\n",
    "    print(doc.metadata)\n",
    "    print('*********************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.docstore.document import Document\n",
    "from tqdm import tqdm\n",
    "\n",
    "info_docs = []\n",
    "\n",
    "for index, chunk in tqdm(enumerate(code_chunks[:2])):\n",
    "    print(f\"Processing chunk: {index+1} / {len(code_chunks)}...\")\n",
    "\n",
    "    info = info_chain.invoke(chunk.page_content)\n",
    "    info_points = parse_bullet_points(info)\n",
    "    source_file_name = chunk.metadata[\"source\"]\n",
    "    info_docs.append(Document(page_content=source_file_name+\"\\n\"+info_points, metadata=chunk.metadata))\n",
    "\n",
    "# persistence\n",
    "print(info_docs)\n",
    "\n",
    "info_store = Chroma.from_documents(info_docs, embedding=gpt4all_embd, persist_directory='.\\\\temp\\\\info_store_lvl_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['4f149d5f-e5b5-4a84-a700-7d613f05ad2e',\n",
       "  '5dc05819-3459-47fb-9397-4ae6b35dac0a'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'source': 'PathTracerAP\\\\Debug_Visualizer.h'},\n",
       "  {'source': 'PathTracerAP\\\\Debug_Visualizer.h'}],\n",
       " 'documents': ['PathTracerAP\\\\Debug_Visualizer.h\\n• Includes the GLEW, GLFW, and GLM libraries for OpenGL functionality.\\n• Includes the Renderer header file.',\n",
       "  'PathTracerAP\\\\Debug_Visualizer.h\\n• This code snippet defines a preprocessor directive #ifdef, indicating that the following block of code should only be compiled if the symbol \"ENABLE_VISUALIZER\" is defined.'],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_store_1 = Chroma(persist_directory=\".\\\\temp\\\\info_store_lvl_1\", embedding_function=gpt4all_embd)\n",
    "info_store_1.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing level: 2\n"
     ]
    }
   ],
   "source": [
    "#Hierarchical summarization\n",
    "\n",
    "read_buffer = info_docs.copy()\n",
    "merge_buffer = []\n",
    "level_index = 2\n",
    "while len(read_buffer) > 1:\n",
    "    print(\"Processing level: \"+str(level_index))\n",
    "    for i in range(0, len(read_buffer)-1, 2):\n",
    "        info = heirarchy_chain.invoke({\"summary_1\":read_buffer[i].page_content, \"summary_2\":read_buffer[i+1].page_content})\n",
    "        info_points = parse_bullet_points(info)\n",
    "        source_list_set = set(read_buffer[i].metadata[\"source\"].split(\"|\")).union(read_buffer[i+1].metadata[\"source\"].split(\"|\"))\n",
    "        source_list_str = \"|\".join(source_list_set)\n",
    "        combined_meta = {\"source\": source_list_str}\n",
    "\n",
    "        merge_buffer.append(Document(page_content=source_list_str+\"\\n\"+info_points, metadata=combined_meta))\n",
    "\n",
    "    read_buffer.clear()\n",
    "    read_buffer.extend(merge_buffer)\n",
    "    info_store_nm = '.\\\\temp\\\\info_store_lvl_'+str(level_index)\n",
    "    info_store = Chroma.from_documents(merge_buffer, embedding=gpt4all_embd, persist_directory=info_store_nm)\n",
    "    level_index = level_index + 1\n",
    "    merge_buffer.clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def process_user_query(message, history):\n",
    "    if len(history) % 2 == 0:\n",
    "        return f\"Yes, I do think that '{message}'\"\n",
    "    else:\n",
    "        return \"I don't think so\"\n",
    "\n",
    "def process_source_code(dir_path):\n",
    "    progress = gr.Progress()\n",
    "    # Simulate file processing with a delay\n",
    "    for i in range(10):\n",
    "        time.sleep(0.5)\n",
    "        progress(i / 10)\n",
    "        a = True\n",
    "\n",
    "# Define Gradio interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# CodeDocBot\")\n",
    "    dir_path = gr.Textbox(label=\"Source-code directory path\", placeholder=\"Enter the path to the folder\")\n",
    "    process_button = gr.Button(\"Process File\")\n",
    "    output_text = gr.Textbox(label=\"\")\n",
    "    \n",
    "    process_button.click(fn=process_source_code, inputs=dir_path, outputs=output_text)\n",
    "\n",
    "demo.launch()\n",
    "gr.ChatInterface(process_user_query).launch()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
